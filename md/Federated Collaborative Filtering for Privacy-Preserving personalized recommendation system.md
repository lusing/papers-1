# Federated Collaborative Filtering for Privacy-Preserving personalized recommendation system

## ABSTRACT

The increasing interest in user privacy is leading to new privacy preserving machine learning paradigms. In the Federated Learning paradigm, a master machine learning model is distributed to user clients, the clients use their locally stored data and model for both inference and calculating model updates. The model updates are sent back and aggregated on the server to update the master model then redistributed to the clients. In this paradigm, the user data never leaves the client, greatly enhancing the user’ privacy, in contrast to the traditional paradigm of collecting, storing and processing user data on a backend server beyond the user’s control. In this paper we introduce, as far as we are aware, the first federated implementation of a Collaborative Filter. The federated updates to the model are based on a stochastic gradient approach. As a classical case study in machine learning, we explore a personalized recommendation system based on users’ implicit feedback and demonstrate the method’s applicability to both the MovieLens and an in-house dataset. Empirical validation confirms a collaborative filter can be federated without a loss of accuracy compared to a standard implementation, hence enhancing the user’s privacy in a widely used recommender application while maintaining recommender performance.

人们对用户隐私越来越感兴趣，这导致了新的隐私保护机器学习范式。在联邦学习范式中，一个主机器学习模型被分发给用户客户机，客户机使用其本地存储的数据和模型进行推理和计算模型更新。模型更新被发回并在服务器上聚合以更新主模型，然后重新分发到客户端。与在用户无法控制的后端服务器上收集、存储和处理用户数据的传统范例相比，在这种范例中，用户数据永远不会离开客户端，这大大增强了用户的隐私。据我们所知，在本文中我们将介绍协作过滤器的第一个联邦实现。该模型的联邦更新基于随机梯度方法。作为机器学习的经典案例，我们探索了基于用户隐式反馈的个性化推荐系统，并展示了该方法对MovieLens和内部数据集的适用性。经验验证证实，与标准实现相比，协作过滤器可以联合起来，而不会损失准确性，因此在一个广泛使用的推荐应用程序中增强了用户的隐私，同时保持了推荐性能。

## Introduction

The General Data Protection Regulation (GDPR) https://gdpr-info.eu/ in the EU (Other jurisdictions are considering similar type legislation and also an increased awareness of users of their data privacy) requires users to be both fully informed about, and consent to the collection, storage, and utilization of their personal data by other parties. GDPR changes the default option of users’ personal data being harvested, stored and used to requiring explicit opt-in from the user. A default opt-in requires users to explicitly consent to the collection and use of their personal data which many fail to do. Low user opt-in rates means less data to build high performance machine learning models which in general decrease the model’s performance.

一般在欧盟数据保护监管(GDPR) https://gdpr-info.eu/(其他司法管辖区也正在考虑类似立法和增加用户的数据隐私的意识)需要用户既充分了解,并同意收集、存储和利用他们的个人数据被其他政党。GDPR改变了收集、存储用户个人数据的默认选项，并习惯于要求用户明确选择。默认选项要求用户明确同意收集和使用他们的个人资料，但很多人没有这样做。低用户选择加入率意味着更少的数据来建立高性能的机器学习模型，这通常会降低模型的性能。

Personalized recommendation, a classical application of machine learning models [1] suffers badly from unreliable predictions with diverse consequences in many different domains. For example in health care, an in-accurate recommendation on treatment choices may fail the patient while in e-commerce a poor personalization service may recommend products or content of no interest to a user, resulting in a bad user experience. There exists a need to develop new machine learning methods that offer a privacy-by-design solution where we no longer need to collect and store the users’ personal data, hence no longer requiring their explicit opt-in to do so, while still making the users’ personal data available for building robust models.

个性化推荐是机器学习模型[1]的经典应用，在许多不同的领域都存在不可靠的预测和不同的结果。例如，在医疗保健领域，对治疗选择的不准确推荐可能会使患者失败，而在电子商务领域，糟糕的个性化服务可能会推荐用户不感兴趣的产品或内容，从而导致糟糕的用户体验。存在一个需要开发新的机器学习方法,提供privacy-by-design解决方案,我们不再需要收集和存储用户的个人数据,因此不再需要他们明确的选择,又能让用户的个人数据用于构建健壮的模型。

Thanks to advances in technology, user devices (e.g. laptops, mobile phones or tablets) have become an integral part of the machine learning process both in terms of being the source of data used in model building and the means of delivering the results of the model (e.g. recommendations) back to the user. These devices may contain user data ranging from very sensitive personal information (e.g. age, gender, location, who like what etc) to the less sensitive (e.g. downloaded applications or videos watched). The standard approach to model building has been to collect user data from these device and transfer it for processing to backend servers. At the servers, the data may be “anonymized” however, anonymization is not foolproof and can still violate user privacy when integrated with other data [2].

由于技术的进步,用户设备(如笔记本电脑、手机或平板电脑)已经成为不可分割的一部分的机器学习过程方面的来源数据用于模型构建和交付的方式模型(如建议)的结果返回给用户。这些设备可能包含用户数据，从非常敏感的个人信息(如年龄、性别、位置、谁喜欢什么等)到不那么敏感的信息(如下载的应用程序或观看的视频)。建立模型的标准方法是从这些设备收集用户数据并将其传输到后端服务器进行处理。在服务器上，数据可能被“匿名化”，然而，匿名化并不是万无一有的，当与其他数据[2]集成时，仍然会侵犯用户隐私。

To tackle this privacy problem, a Federated Learning (FL) method has been proposed recently [3]. Federated learning distributes the model learning process to the end clients (i.e. user’s devices), making it possible to train a global model from user-specific local models, ensuring that the user’s private data never leaves the client device enhancing the users privacy. Their proposed FL method is specific to deep learning models with use cases in image recognition and language modeling tasks. Collaborative Filtering CF (we interchangeably use the abbreviation “CF” for both Collaborative Filtering and Collaborative Filter) is one of the most frequently used matrix factorization models to generate personalized recommendations either independently or combined with other types of models [4]. Particularly, CF utilizes user data to build models and generate recommendations for users, in different contexts [5].

为了解决这个隐私问题，最近提出了一种联邦学习(FL)方法[3]。联邦学习将模型学习过程分发给最终客户端(即用户的设备)，使从用户特定的本地模型训练出全局模型成为可能，确保用户的隐私数据不会离开客户端设备，增强了用户的隐私性。他们提出的FL方法专门用于深度学习模型，在图像识别和语言建模任务中有使用案例。协同过滤CF(我们可以将协同过滤和协同过滤的缩写“CF”互换使用)是最常用的矩阵分解模型之一，可以独立生成个性化推荐，也可以与其他类型的模型[4]相结合。特别是，CF利用用户数据为不同上下文[5]中的用户构建模型并生成推荐。

In this paper, we introduce the first Federated Collaborative Filter (FCF) method. We show that federation of the collaborative filter is technically challenging and formulate the updates using a stochastic gradient-based approach. Our method aggregates user-specific gradient updates of the model weights from the clients to update the master model. Specifically, we derive a federated version of the widely used CF method for implicit feedback datasets [6]. However, the proposed method is generalizable and can be extended to recommendation scenarios where explicit rating information is available and can also be applied to a more generic class of matrix factorization models. We compare results between the standard and federated models on a simulated dataset as well as on two real datasets, MovieLens and an in-house service dataset. The findings confirm that the performance of the proposed FCF method is statistically similar compared to the CF model, implying no loss of accuracy while simultaneously enhancing user privacy.

本文介绍了第一种联邦协同过滤(FCF)方法。我们证明了联合的协作过滤器是具有技术挑战性的，并使用基于随机梯度的方法来制定更新。我们的方法从客户端聚合特定于用户的模型权重梯度更新来更新主模型。具体来说，我们为隐式反馈数据集[6]推导了广泛使用的CF方法的联邦版本。然而，所提出的方法是一般化的，可以扩展到有明确评级信息的推荐场景，也可以应用于更一般的矩阵分解模型。我们比较了一个模拟数据集以及两个真实数据集(MovieLens和一个内部服务数据集)上的标准模型和联邦模型的结果。研究结果证实，与CF模型相比，所提出的FCF方法的性能在统计上是相似的，这意味着在提高用户隐私性的同时没有丢失准确性。

## Related Work

## Collaborative Filter

## 
