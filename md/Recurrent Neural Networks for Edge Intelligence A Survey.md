# Recurrent Neural Networks for Edge Intelligence: A Survey

Recurrent Neural Networks are ubiquitous and pervasive in many artificial intelligence applications such as speech recognition, predictive healthcare, creative art, and so on. Although they provide accurate superior solutions, they pose a massive challenge “training havoc.” Current expansion of IoT demands intelligent models to be deployed at the edge. This is precisely to handle increasing model sizes and complex network architectures. Design efforts to meet these for greater performance have had inverse effects on portability on edge devices with real-time constraints of memory, latency, and energy. This article provides a detailed insight into various compression techniques widely disseminated in the deep learning regime. They have become key in mapping powerful RNNs onto resource-constrained devices. While compression of RNNs is the main focus of the survey, it also highlights challenges encountered while training. The training procedure directly influences model performance and compression alongside. Recent advancements to overcome the training challenges with their strengths and drawbacks are discussed. In short, the survey covers the three-step process, namely, architecture selection, efficient training process, and suitable compression technique applicable to a resource-constrained environment. It is thus one of the comprehensive survey guides a developer can adapt for a time-series problem context and an RNN solution for the edge.

循环神经网络在许多人工智能应用中无处不在，如语音识别、预测医疗、创意艺术等。尽管它们提供了准确的卓越解决方案，但它们构成了“训练破坏”的巨大挑战。当前物联网的扩展需要在边缘部署智能模型。这正是为了处理不断增加的模型大小和复杂的网络架构。为满足这些以提高性能而进行的设计工作对具有实时内存、延迟和能量限制的边缘设备的便携性产生了负面影响。本文详细介绍了在深度学习机制中广泛传播的各种压缩技术。它们已成为将强大的 RNN 映射到资源受限设备上的关键。虽然 RNN 的压缩是调查的主要焦点，但它也突出了训练过程中遇到的挑战。训练过程直接影响模型性能和压缩。讨论了克服培训挑战的最新进展及其优缺点。简而言之，该调查涵盖了三步过程，即架构选择、高效训练过程和适用于资源受限环境的合适压缩技术。因此，它是开发人员可以适应时间序列问题上下文和边缘 RNN 解决方案的综合调查指南之一。

